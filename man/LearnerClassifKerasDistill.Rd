% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/LearnerKerasDistill.R
\name{LearnerClassifKerasDistill}
\alias{LearnerClassifKerasDistill}
\alias{mlr_learners_classif.kerasdistill}
\title{Keras Feed Forward Neural Network for Knowledge Distillation}
\format{
[R6::R6Class()] inheriting from [mlr3keras::LearnerClassifKerasFF].
}
\description{
Internally, samples new observations from the task data using a nonparametric sampling
technique (here: Munge (c.f. Caruana et al., 2011 Model Compression).
Those observations are then labeled using the supplied `teacher`; a fitted `mlr3` learner.
In addition to all hyperparameters from `kerasff`, this learner has the following
hyperparameters which allow for control over the distillation process:
* `n` :: number of artificial rows to sample
* `switch_prob` :: probability to switch out each entry with it's nearest neighbour
* `var` :: For numeric features, a new value is sampled from N(x_nn, |x -x_nn| / var)
  where x is a feature value, x_nn the nearest neighbour's corresponding feature value.
* `probabilities` :: Should probabilities be approximated instead of the response?
  (c.f. Hinton, 2015 Dark Knowledge)
* `alpha` :: Specifies a convex-combination of labels predicted by the learner (alpha = 0)
  and labels of the observation before swapping.

Feed Forward Neural Network using Keras and Tensorflow.
This learner builds and compiles the keras model from the hyperparameters in `param_set`,
and does not require a supplied and compiled model.

Calls [keras::fit] from package \CRANpkg{keras}.
Layers are set up as follows:
* The inputs are connected to a `layer_dropout`, applying the `input_dropout`.
  Afterwards, each `layer_dense()` is followed by a `layer_activation`, and
  depending on hyperparameters by a `layer_batch_normalization` and or a
  `layer_dropout` depending on the architecture hyperparameters.
  This is repeated `length(layer_units)` times, i.e. one
  'dense->activation->batchnorm->dropout' block is appended for each `layer_unit`.
  The last layer is either 'softmax' or 'sigmoid' for classification or
  'linear' or 'sigmoid' for regression.

Parameters:\cr
Most of the parameters can be obtained from the `keras` documentation.
Some exceptions are documented here.
* `use_embedding`: A logical flag, should embeddings be used?
  Either uses `make_embedding` (if TRUE) or if set to FALSE `model.matrix(~. - 1, data)`
  to convert factor, logical and ordered factors into numeric features.
* `layer_units`: An integer vector storing the number of units in each
  consecutive layer. `layer_units = c(32L, 32L, 32L)` results in a 3 layer
  network with 32 neurons in each layer.
  Can be `integer(0)`, in which case we fit a (multinomial) logistic regression model.

* `initializer`: Weight and bias initializer.
  ```
  "glorot_uniform"  : initializer_glorot_uniform(seed)
  "glorot_normal"   : initializer_glorot_normal(seed)
  "he_uniform"      : initializer_he_uniform(seed)
  "..."             : see `??keras::initializer`
  ```

* `optimizer`: Some optimizers and their arguments can be found below.\cr
  Inherits from `tensorflow.python.keras.optimizer_v2`.
  ```
  "sgd"     : optimizer_sgd(lr, momentum, decay = decay),
  "rmsprop" : optimizer_rmsprop(lr, rho, decay = decay),
  "adagrad" : optimizer_adagrad(lr, decay = decay),
  "adam"    : optimizer_adam(lr, beta_1, beta_2, decay = decay),
  "nadam"   : optimizer_nadam(lr, beta_1, beta_2, schedule_decay = decay)
  ```

* `regularizer`: Regularizer for keras layers:
  ```
  "l1"      : regularizer_l1(l = 0.01)
  "l2"      : regularizer_l2(l = 0.01)
  "l1_l2"   : regularizer_l1_l2(l1 = 0.01, l2 = 0.01)
  ```

* `class_weights`: needs to be a named list of class-weights
  for the different classes numbered from 0 to c-1 (for c classes).
  ```
  Example:
  wts = c(0.5, 1)
  setNames(as.list(wts), seq_len(length(wts)) - 1)
  ```
* `callbacks`: A list of keras callbacks.
  See `?callbacks`.
}
\section{Construction}{

```
LearnerClassifKerasDistill$new()
mlr3::mlr_learners$get("classif.kerasdistill")
mlr3::lrn("classif.kerasdistill")
```
}

\section{Learner Methods}{


Keras Learners offer several methods for easy access to the
stored models.

* `.$plot()`\cr
  Plots the history, i.e. the train-validation loss during training.
* `.$save(file_path)`\cr
  Dumps the model to a provided file_path in 'h5' format.
* `.$load_model_from_file(file_path)`\cr
  Loads a model saved using `saved` back into the learner.
  The model needs to be saved separately when the learner is serialized.
  In this case, the learner can be restored from this function.
  Currently not implemented for 'TabNet'.
}

\examples{
learner = mlr3::lrn("classif.kerasdistill")
print(learner)

# available parameters:
learner$param_set$ids()
}
\seealso{
[Dictionary][mlr3misc::Dictionary] of [Learners][mlr3::Learner]: [mlr3::mlr_learners]
}
\section{Super classes}{
\code{\link[mlr3:Learner]{mlr3::Learner}} -> \code{\link[mlr3:LearnerClassif]{mlr3::LearnerClassif}} -> \code{\link[mlr3keras:LearnerClassifKeras]{mlr3keras::LearnerClassifKeras}} -> \code{\link[mlr3keras:LearnerClassifKerasFF]{mlr3keras::LearnerClassifKerasFF}} -> \code{LearnerClassifKerasDistill}
}
\section{Public fields}{
\if{html}{\out{<div class="r6-fields">}}
\describe{
\item{\code{teacher}}{[`Learner`] \cr
Trained method to distill into a neural network}
}
\if{html}{\out{</div>}}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-new}{\code{LearnerClassifKerasDistill$new()}}
\item \href{#method-clone}{\code{LearnerClassifKerasDistill$clone()}}
}
}
\if{html}{
\out{<details ><summary>Inherited methods</summary>}
\itemize{
\item \out{<span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="format">}\href{../../mlr3/html/Learner.html#method-format}{\code{mlr3::Learner$format()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="help">}\href{../../mlr3/html/Learner.html#method-help}{\code{mlr3::Learner$help()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="predict">}\href{../../mlr3/html/Learner.html#method-predict}{\code{mlr3::Learner$predict()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="predict_newdata">}\href{../../mlr3/html/Learner.html#method-predict_newdata}{\code{mlr3::Learner$predict_newdata()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="print">}\href{../../mlr3/html/Learner.html#method-print}{\code{mlr3::Learner$print()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="reset">}\href{../../mlr3/html/Learner.html#method-reset}{\code{mlr3::Learner$reset()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="train">}\href{../../mlr3/html/Learner.html#method-train}{\code{mlr3::Learner$train()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="mlr3keras" data-topic="LearnerClassifKeras" data-id="load_model_from_file">}\href{../../mlr3keras/html/LearnerClassifKeras.html#method-load_model_from_file}{\code{mlr3keras::LearnerClassifKeras$load_model_from_file()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="mlr3keras" data-topic="LearnerClassifKeras" data-id="lr_find">}\href{../../mlr3keras/html/LearnerClassifKeras.html#method-lr_find}{\code{mlr3keras::LearnerClassifKeras$lr_find()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="mlr3keras" data-topic="LearnerClassifKeras" data-id="plot">}\href{../../mlr3keras/html/LearnerClassifKeras.html#method-plot}{\code{mlr3keras::LearnerClassifKeras$plot()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="mlr3keras" data-topic="LearnerClassifKeras" data-id="save">}\href{../../mlr3keras/html/LearnerClassifKeras.html#method-save}{\code{mlr3keras::LearnerClassifKeras$save()}}\out{</span>}
}
\out{</details>}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-new"></a>}}
\if{latex}{\out{\hypertarget{method-new}{}}}
\subsection{Method \code{new()}}{
Creates a new instance of this [R6][R6::R6Class] class.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LearnerClassifKerasDistill$new(teacher)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{teacher}}{[`Learner`] \cr
Trained learner to compress into a neural network.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-clone"></a>}}
\if{latex}{\out{\hypertarget{method-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LearnerClassifKerasDistill$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
